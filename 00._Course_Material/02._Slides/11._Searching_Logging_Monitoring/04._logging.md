<div class="title-card">
    <h1>Logging vs. Monitoring vs. Tracing vs. Profiling</h1>
</div>


---

# Logging vs. Monitoring vs. Tracing vs. Profiling

**Logging**: Record events in a software system.

**Monitoring**: Observe the system.

**Tracing**: Record the sequence in which events propagate through the system (especially useful for distributed systems).

**Profiling**: Measure the performance.

---

# Tracing

End-to-end journey of a request across a distributed system. 

Keeps track of how a request flows through various services.

**Not logging**: it focuses on the path and latency across services rather than discrete events.

**Not monitoring**: it focuses on individual request paths rather than system-wide metrics.

---

# Profiling

> "In software engineering, profiling ("program profiling", "software profiling") is a form of dynamic program analysis that measures, for example, the space (memory) or time complexity of a program, the usage of particular instructions, or the frequency and duration of function calls."

<a href="https://en.wikipedia.org/wiki/Profiling_(computer_programming)">Source: Wikipedia</a>

Jmeter, Gatling, Locust, etc.

**Not logging**: Doesn't record descrite events or historical data. 

**Not monitoring**: Doesn't track system-wide metrics over time. 

---

<div class="title-card">
    <h1>Logging</h1>
</div>

---

# Logging

The activity of collecting and analyzing data generated by applications, infrastructure, and other components of a system.

- **Streams** of

- **aggregated**

- **time-ordered** events

- collected from **running processes**

---

# Why log?

*Why would you need need to log?*

---

# Why log?

1. **Diagnosis**: What went wrong. 

2. **Anomaly detection**: Perform statistical analysis to find outliers and variances. 

3. **Understanding**: How is your system being used?

4. **Security**: Detecting unauthorized access.

5. **Compliance**: Legal requirements to create audit trails. 

---

# Motivation: Logging is big business

> "Dansk IT-sikkerhedsvirksomhed solgt for ukendt stort milliardbeløb"

https://finans.dk/erhverv/ECE15230842/dansk-itsikkerhedsvirksomhed-solgt-for-ukendt-stort-milliardbeloeb/

**LogPoint** specializes in in SIEM (Security Information and Event Management).

There are many such companies and they are all very profitable.

---

# Where to log to?

**On the same server as the application**

It is perfectly fine to log on the same server as the application. 

In Linux there is a `var/log` meant for exactly this. Example: `var/log/name_of_the_log_file.log`

You should decouple your logs from your code and not keep it in the repository. *Why?*

<details> 
  <summary>Answer</summary>

    1. You do not wish to check in logs to the repository.
    2. Mixing logs with the code makes it could make it harder to do normal push/pull operations or straight up deleting the repository and recloning it. 
</details>

**A logging server**

Logstash, Splunk, Graylog, etc.


---

# What not to log?

**NEVER** log sensitive data like passwords, credit card numbers, etc.

If it is personal data (as defined by GDPR) there are rules such as the right to be forgotten, deleting data after a certain time period etc.

Mixing personal data with the logs will make it an impossible task to comply with these rules.

*How can you solve this?*

<details> 
  <summary>Answer</summary>
  Create an ID for the sensitive data and store it somewhere else from your logs. 
  Bonus points if the ID is different from the IDs in your application database for an added layer of security.
</details>


---

<div class="title-card">
    <h1>Logging formats</h1>
</div>

---

# Syslog

* Developed in 80s

* Standardizes **formatting** and **transmission** of logs in a network ([RFC 3164 (2001)](https://tools.ietf.org/html/rfc3164), [RFC 5424 (2009)](https://tools.ietf.org/html/rfc5424))

* Popular in Linux

* General - for any system exchanging logs

---

# Syslog - Format

<img src="./assets_logging/syslog_format.png" alt="syslog format">

[Source: Stackifly / Flylib](https://stackify.com/syslog-101/)

https://en.wikipedia.org/wiki/Syslog

---

# A syslog compliant Python example

```python
import sys
import logging
import socket

logging.basicConfig(
    format="%(asctime)s %(hostname)s %(module)s[%(process)d]: %(levelname)s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    level=logging.INFO,
    stream=sys.stdout
)

# Add hostname dynamically
logging.Logger.adapter = logging.LoggerAdapter(logging.getLogger(), {'hostname': socket.gethostname()})

logging.debug('This is a debug message in the syslog format')
```


---

# Common logging levels


| Logging Level | Description                                                                                                                                          |
|---------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| **DEBUG**     | Information about anything that happens in the program, often used during debugging. Debug logs are usually disabled in production but enabled temporarily during troubleshooting. |
| **INFO**      | Actions that are user-driven or system-specific (e.g., “beginning credit card transaction”).                                                         |
| **WARN**      | Conditions that could potentially become an error (e.g., a database call taking longer than some predefined time). These often initiate alerts and troubleshooting. |
| **ERROR**     | Focuses on error conditions (e.g., API call failures, internal error conditions).                                                                    |
| **FATAL**     | Indicates when we must terminate (e.g., a network daemon can’t bind a network socket).                                                     |

Additionally, Syslog has `Notice`, `Critical`, `Alert` and  `Emergency` but does not have `Fatal`. 

https://en.wikipedia.org/wiki/Syslog#Severity_level

---

# Logging levels - Python Example


The smart thing is that you can use the logging levels to filter out output.

Example with `logging` which is part of the Python standard library:

```python
import logging

logging.basicConfig(level=logging.INFO)

logging.debug('This is a debug message')
logging.info('This is an info message')
logging.warning('This is a warning message')
logging.error('This is an error message')
logging.critical('This is a critical message')
```

**Question**: *Can you guess what will be shown?*

---

# Logging levels - What will be shown

```python
import logging

logging.basicConfig(level=logging.INFO)

logging.debug("Oops, got here.")                           # This will not be shown
logging.info("User updated preferences.")                  # This will be shown
logging.warning("Could not retrieve any items from feed.") # This will be shown
logging.error("Google Translate API not answering")        # This will be shown
logging.critical("Out of memory")                          # This will be shown
```

---

# Logging levels - Display levels

| Logging Level | Displays Messages at Levels |
|---------------|-----------------------------|
| **DEBUG**     | DEBUG, INFO, WARNING, ERROR, CRITICAL |
| **INFO**      | INFO, WARNING, ERROR, CRITICAL |
| **WARNING**   | WARNING, ERROR, CRITICAL     |
| **ERROR**     | ERROR, CRITICAL              |
| **CRITICAL**  | CRITICAL                     |


---

<div class="title-card">
    <h1>Logging stacks</h1>
</div>

---

# ELK stack

* ElasticSearch = Scalable full text search DB

* Logstash = Java-based log parser

* Kibana = Visualization tool tailored for ElasticSearch

---

# Other common logging stacks

* **ELK stack**: Elasticsearch, Logstash, Kibana

* **EFLK stack**: Elasticsearch, Filebeat, Logstash, Kibana

* **EFK stack**: Elasticsearch, Fluentd, Kibana

* **Graylog**: Graylog server, MongoDB, Elasticsearch, Graylog web interface

* **Loki + Grafana**: Loki, Grafana

Then there are single-purpose tools like **Splunk**, **Loggly**, **Sumo Logic**, **Papertrail**, **LogDNA**, **Datadog** and many more.

You can always do it yourself! That's what the `simulator` and `plot server` does.

---

# The Logfile Navigator

A cool terminal-based tool to view and analyze log files in real-time.

Try out the playground on their website:

https://lnav.org/

---

# Docker and logging

Access logs in docker:

```bash
$ docker logs <container_id>
```

**Note**: When you are running containers if you don't collect and ship the logs, they'll disappear when you restart (or destroy) the container

Create a new container that will store the logs in the syslog format:

```bash
$ docker run --log-driver=syslog <image>
```

Attach logs to host logs (map container log files to a directory on the host system):

```yaml
volumes:
  - /host/logs:/var/log/container
```

---

# Course requirements regarding logging

You are not required to implement logging. At least in this iteration of the course. 

Implementing the ELK stack is time consuming and requires a lot of resources such as memory.

But if you can manage to implement logging then feel free to do so. 

You could leverage the logging system in your framework. For instance, `.NET Core` has an excellent built-in logging system.